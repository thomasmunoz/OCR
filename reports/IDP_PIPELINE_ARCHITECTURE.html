<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>IDP Pipeline - Complete Architecture</title>
    <script src="https://cdn.jsdelivr.net/npm/mermaid@10.9.0/dist/mermaid.min.js"></script>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'SF Pro Display', sans-serif;
            background: linear-gradient(135deg, #0a0a14 0%, #1a1a2e 50%, #0f2744 100%);
            min-height: 100vh;
            color: #e0e0e0;
            line-height: 1.6;
        }
        .container { max-width: 1400px; margin: 0 auto; padding: 2rem; }

        header {
            text-align: center;
            padding: 3rem 2rem;
            background: linear-gradient(135deg, rgba(124,58,237,0.2), rgba(37,99,235,0.2));
            border-radius: 20px;
            margin-bottom: 2rem;
            border: 1px solid rgba(124,58,237,0.3);
        }
        h1 {
            font-size: 3rem;
            background: linear-gradient(135deg, #00d4ff, #7c3aed, #f472b6);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            margin-bottom: 1rem;
        }
        .subtitle { color: #a0a0a0; font-size: 1.2rem; }
        .badges { margin-top: 1.5rem; display: flex; justify-content: center; gap: 1rem; flex-wrap: wrap; }
        .badge {
            padding: 0.5rem 1rem;
            border-radius: 20px;
            font-size: 0.85rem;
            font-weight: 600;
        }
        .badge-green { background: rgba(16,185,129,0.2); color: #10b981; border: 1px solid #10b981; }
        .badge-blue { background: rgba(59,130,246,0.2); color: #3b82f6; border: 1px solid #3b82f6; }
        .badge-purple { background: rgba(124,58,237,0.2); color: #a78bfa; border: 1px solid #7c3aed; }

        section {
            background: rgba(255,255,255,0.03);
            border-radius: 16px;
            padding: 2rem;
            margin-bottom: 2rem;
            border: 1px solid rgba(255,255,255,0.08);
        }
        section h2 {
            font-size: 1.5rem;
            margin-bottom: 1.5rem;
            color: #00d4ff;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        section h3 {
            font-size: 1.2rem;
            margin: 1.5rem 0 1rem;
            color: #a78bfa;
        }

        .mermaid {
            background: rgba(0,0,0,0.3);
            border-radius: 12px;
            padding: 1.5rem;
            margin: 1rem 0;
            overflow-x: auto;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1rem 0;
        }
        th, td {
            padding: 1rem;
            text-align: left;
            border-bottom: 1px solid rgba(255,255,255,0.1);
        }
        th { color: #a0a0a0; font-weight: 500; font-size: 0.85rem; text-transform: uppercase; }
        tr:hover { background: rgba(255,255,255,0.02); }

        code {
            background: rgba(0,0,0,0.4);
            padding: 0.2rem 0.5rem;
            border-radius: 4px;
            font-family: 'SF Mono', Monaco, monospace;
            font-size: 0.9rem;
            color: #10b981;
        }
        pre {
            background: rgba(0,0,0,0.4);
            padding: 1.5rem;
            border-radius: 12px;
            overflow-x: auto;
            font-family: 'SF Mono', Monaco, monospace;
            font-size: 0.85rem;
            line-height: 1.5;
            color: #e0e0e0;
        }

        .grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 1.5rem; }

        .card {
            background: rgba(0,0,0,0.2);
            border-radius: 12px;
            padding: 1.5rem;
            border: 1px solid rgba(255,255,255,0.08);
        }
        .card h4 {
            font-size: 1.1rem;
            margin-bottom: 0.5rem;
            color: #f472b6;
        }
        .card p { color: #a0a0a0; font-size: 0.9rem; }

        .highlight { background: linear-gradient(135deg, rgba(124,58,237,0.2), rgba(37,99,235,0.2)); }

        .model-tag {
            display: inline-block;
            padding: 0.3rem 0.6rem;
            border-radius: 6px;
            font-size: 0.8rem;
            margin: 0.2rem;
        }
        .model-ocr { background: rgba(59,130,246,0.3); color: #93c5fd; }
        .model-org { background: rgba(16,185,129,0.3); color: #6ee7b7; }
        .model-rec { background: rgba(251,191,36,0.3); color: #fcd34d; border: 1px solid #fbbf24; }

        .step {
            display: flex;
            align-items: flex-start;
            gap: 1rem;
            margin: 1rem 0;
            padding: 1rem;
            background: rgba(0,0,0,0.2);
            border-radius: 10px;
        }
        .step-num {
            background: linear-gradient(135deg, #7c3aed, #3b82f6);
            color: white;
            width: 36px;
            height: 36px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            flex-shrink: 0;
        }
        .step-content h4 { margin-bottom: 0.3rem; color: #e0e0e0; }
        .step-content p { color: #a0a0a0; font-size: 0.9rem; }

        footer {
            text-align: center;
            padding: 2rem;
            color: #6b7280;
            font-size: 0.9rem;
        }

        @media (max-width: 768px) {
            h1 { font-size: 2rem; }
            .container { padding: 1rem; }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>IDP Pipeline</h1>
            <p class="subtitle">Intelligent Document Processing - 100% On-Premise</p>
            <div class="badges">
                <span class="badge badge-green">100% Local</span>
                <span class="badge badge-blue">HuggingFace Models</span>
                <span class="badge badge-purple">Smart Model Selection</span>
            </div>
        </header>

        <!-- Overview -->
        <section>
            <h2>System Overview</h2>
            <div class="mermaid">
flowchart TB
    subgraph Input["Input Layer"]
        upload["File Upload"]
        api["API Endpoint"]
        cli["CLI Interface"]
    end

    subgraph Queue["Queue System"]
        queue["SQLite Queue"]
        priority["Priority Manager"]
    end

    subgraph Router["Smart Router"]
        analyze["File Analyzer"]
        selector["Model Selector"]
    end

    subgraph OCR["Stage 1: OCR"]
        ocrEngine["OCR Engine Pool"]
        qwen2vl["Qwen2-VL"]
        gotocr["GOT-OCR 2.0"]
        trocr["TrOCR"]
        florence["Florence-2"]
    end

    subgraph Intermediate["Intermediate Format"]
        json1["OCR JSON"]
        confidence["Confidence Scores"]
        tables["Table Data"]
    end

    subgraph Org["Stage 2: Organization"]
        orgEngine["Organization Engine"]
        qwen25["Qwen2.5"]
        llama32["Llama 3.2"]
        mistral["Mistral 7B"]
    end

    subgraph Output["Output Layer"]
        finalJson["Structured JSON"]
        dashboard["Dashboard"]
        export["Export API"]
    end

    upload --> queue
    api --> queue
    cli --> queue

    queue --> priority
    priority --> analyze
    analyze --> selector

    selector --> ocrEngine
    ocrEngine --> qwen2vl
    ocrEngine --> gotocr
    ocrEngine --> trocr
    ocrEngine --> florence

    qwen2vl --> json1
    gotocr --> json1
    trocr --> json1
    florence --> json1

    json1 --> confidence
    json1 --> tables

    confidence --> orgEngine
    tables --> orgEngine

    orgEngine --> qwen25
    orgEngine --> llama32
    orgEngine --> mistral

    qwen25 --> finalJson
    llama32 --> finalJson
    mistral --> finalJson

    finalJson --> dashboard
    finalJson --> export
            </div>
        </section>

        <!-- Pipeline Flow -->
        <section>
            <h2>Processing Pipeline</h2>
            <div class="mermaid">
sequenceDiagram
    participant U as User
    participant Q as Queue
    participant R as Router
    participant O as OCR Engine
    participant G as Organizer
    participant D as Dashboard

    U->>Q: Submit Document
    Q->>Q: Create Job (pending)
    Q->>R: Get Next Job

    R->>R: Analyze File Format
    R->>R: Detect Language
    R->>R: Select Best OCR Model
    R->>R: Select Best Org Model

    R->>O: Process with Selected OCR
    O->>O: Load Model if Needed
    O->>O: Extract Text + Confidence
    O-->>D: Progress Update (50%)
    O->>Q: Save Intermediate Result

    Q->>G: Continue to Organization
    G->>G: Load Model if Needed
    G->>G: Structure into JSON
    G-->>D: Progress Update (90%)
    G->>Q: Save Final Result

    Q->>Q: Mark Completed
    Q-->>D: Job Complete
    D->>U: Show Results
            </div>
        </section>

        <!-- OCR Models -->
        <section>
            <h2>Stage 1: OCR Models</h2>
            <p style="color:#a0a0a0;margin-bottom:1rem;">Smart selection based on document format, language, and quality requirements.</p>

            <table>
                <thead>
                    <tr>
                        <th>Model</th>
                        <th>HuggingFace Repo</th>
                        <th>Best For</th>
                        <th>VRAM</th>
                        <th>Quality</th>
                        <th>Speed</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><span class="model-tag model-rec">GOT-OCR 2.0</span></td>
                        <td><code>ucaslcl/GOT-OCR2_0</code></td>
                        <td>Complex documents, tables</td>
                        <td>8 GB</td>
                        <td>98/100</td>
                        <td>60/100</td>
                    </tr>
                    <tr>
                        <td><span class="model-tag model-ocr">Qwen2-VL-7B</span></td>
                        <td><code>Qwen/Qwen2-VL-7B-Instruct</code></td>
                        <td>Multi-language, all formats</td>
                        <td>16 GB</td>
                        <td>95/100</td>
                        <td>50/100</td>
                    </tr>
                    <tr>
                        <td><span class="model-tag model-rec">Qwen2-VL-2B</span></td>
                        <td><code>Qwen/Qwen2-VL-2B-Instruct</code></td>
                        <td>Best ROI, multi-language</td>
                        <td>6 GB</td>
                        <td>88/100</td>
                        <td>80/100</td>
                    </tr>
                    <tr>
                        <td><span class="model-tag model-ocr">Florence-2-Large</span></td>
                        <td><code>microsoft/Florence-2-large</code></td>
                        <td>Document understanding</td>
                        <td>6 GB</td>
                        <td>92/100</td>
                        <td>70/100</td>
                    </tr>
                    <tr>
                        <td><span class="model-tag model-ocr">TrOCR-Printed</span></td>
                        <td><code>microsoft/trocr-large-printed</code></td>
                        <td>English printed text</td>
                        <td>2 GB</td>
                        <td>90/100</td>
                        <td>75/100</td>
                    </tr>
                    <tr>
                        <td><span class="model-tag model-ocr">TrOCR-Handwritten</span></td>
                        <td><code>microsoft/trocr-large-handwritten</code></td>
                        <td>Handwritten text</td>
                        <td>2 GB</td>
                        <td>88/100</td>
                        <td>75/100</td>
                    </tr>
                    <tr>
                        <td><span class="model-tag model-ocr">Surya-OCR</span></td>
                        <td><code>vikp/surya_rec</code></td>
                        <td>Fast multi-language</td>
                        <td>2 GB</td>
                        <td>82/100</td>
                        <td>90/100</td>
                    </tr>
                </tbody>
            </table>
        </section>

        <!-- Organization Models -->
        <section>
            <h2>Stage 2: Organization Models</h2>
            <p style="color:#a0a0a0;margin-bottom:1rem;">Transform OCR output into structured, queryable JSON.</p>

            <table>
                <thead>
                    <tr>
                        <th>Model</th>
                        <th>HuggingFace Repo</th>
                        <th>Context</th>
                        <th>VRAM</th>
                        <th>Quality</th>
                        <th>Speed</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><span class="model-tag model-org">Qwen2.5-7B</span></td>
                        <td><code>Qwen/Qwen2.5-7B-Instruct</code></td>
                        <td>128K</td>
                        <td>16 GB</td>
                        <td>95/100</td>
                        <td>60/100</td>
                    </tr>
                    <tr>
                        <td><span class="model-tag model-rec">Llama-3.2-3B</span></td>
                        <td><code>meta-llama/Llama-3.2-3B-Instruct</code></td>
                        <td>128K</td>
                        <td>8 GB</td>
                        <td>88/100</td>
                        <td>80/100</td>
                    </tr>
                    <tr>
                        <td><span class="model-tag model-org">Mistral-7B</span></td>
                        <td><code>mistralai/Mistral-7B-Instruct-v0.3</code></td>
                        <td>32K</td>
                        <td>16 GB</td>
                        <td>90/100</td>
                        <td>70/100</td>
                    </tr>
                    <tr>
                        <td><span class="model-tag model-org">Phi-3.5-mini</span></td>
                        <td><code>microsoft/Phi-3.5-mini-instruct</code></td>
                        <td>128K</td>
                        <td>8 GB</td>
                        <td>85/100</td>
                        <td>85/100</td>
                    </tr>
                    <tr>
                        <td><span class="model-tag model-org">Gemma-2-2B</span></td>
                        <td><code>google/gemma-2-2b-it</code></td>
                        <td>8K</td>
                        <td>6 GB</td>
                        <td>82/100</td>
                        <td>90/100</td>
                    </tr>
                    <tr>
                        <td><span class="model-tag model-org">Qwen2.5-1.5B</span></td>
                        <td><code>Qwen/Qwen2.5-1.5B-Instruct</code></td>
                        <td>128K</td>
                        <td>4 GB</td>
                        <td>78/100</td>
                        <td>95/100</td>
                    </tr>
                </tbody>
            </table>
        </section>

        <!-- Smart Router -->
        <section class="highlight">
            <h2>Smart Model Router</h2>
            <div class="mermaid">
flowchart LR
    subgraph Input["Input Analysis"]
        format["File Format"]
        lang["Language Detection"]
        complexity["Complexity Score"]
        vram["Available VRAM"]
    end

    subgraph Rules["Selection Rules"]
        formatRule["Format Rules"]
        langRule["Language Rules"]
        qualityRule["Quality Priority"]
    end

    subgraph Selection["Model Selection"]
        ocrSelect["OCR Model"]
        orgSelect["Org Model"]
    end

    format --> formatRule
    lang --> langRule
    complexity --> qualityRule
    vram --> formatRule
    vram --> langRule

    formatRule --> ocrSelect
    langRule --> ocrSelect
    qualityRule --> ocrSelect

    ocrSelect --> orgSelect
            </div>

            <h3>Selection Logic</h3>
            <div class="grid">
                <div class="card">
                    <h4>PDF Complex</h4>
                    <p>Multi-column, tables, mixed content</p>
                    <p style="margin-top:0.5rem;">
                        <span class="model-tag model-ocr">GOT-OCR 2.0</span>
                        <span class="model-tag model-ocr">Qwen2-VL-7B</span>
                    </p>
                </div>
                <div class="card">
                    <h4>CJK Languages</h4>
                    <p>Chinese, Japanese, Korean</p>
                    <p style="margin-top:0.5rem;">
                        <span class="model-tag model-ocr">Qwen2-VL-7B</span>
                        <span class="model-tag model-ocr">GOT-OCR 2.0</span>
                    </p>
                </div>
                <div class="card">
                    <h4>Handwritten</h4>
                    <p>Handwritten text recognition</p>
                    <p style="margin-top:0.5rem;">
                        <span class="model-tag model-ocr">TrOCR-Handwritten</span>
                        <span class="model-tag model-ocr">Qwen2-VL-7B</span>
                    </p>
                </div>
                <div class="card">
                    <h4>Speed Priority</h4>
                    <p>Fast processing, good quality</p>
                    <p style="margin-top:0.5rem;">
                        <span class="model-tag model-ocr">Surya-OCR</span>
                        <span class="model-tag model-org">Gemma-2-2B</span>
                    </p>
                </div>
            </div>
        </section>

        <!-- Intermediate Format -->
        <section>
            <h2>Intermediate Format</h2>
            <p style="color:#a0a0a0;margin-bottom:1rem;">Optimized structure for Stage 2 processing with full confidence tracking.</p>

            <pre>{
  "version": "1.0",
  "job_id": "abc123",
  "metadata": {
    "source_file": "/path/to/document.pdf",
    "source_format": "pdf",
    "source_hash": "sha256...",
    "ocr_model_used": "Qwen2-VL-2B",
    "ocr_timestamp": "2025-12-25T12:00:00Z",
    "ocr_duration_seconds": 4.5,
    "detected_language": "en",
    "total_pages": 3,
    "average_confidence": 0.92,
    "low_confidence_count": 2
  },
  "pages": [
    {
      "page_number": 1,
      "raw_text": "...",
      "confidence": 0.94,
      "blocks": [
        {
          "block_type": "paragraph",
          "text": "...",
          "confidence": 0.95,
          "lines": [
            {
              "text": "Invoice #12345",
              "confidence": 0.98,
              "confidence_level": "certain"
            }
          ]
        }
      ],
      "tables": [
        {
          "rows": 5,
          "cols": 3,
          "confidence": 0.89,
          "matrix": [["Item", "Qty", "Price"], ...]
        }
      ]
    }
  ],
  "confidence_distribution": {
    "certain_95_100": 45,
    "high_80_94": 30,
    "medium_60_79": 20,
    "low_40_59": 5,
    "uncertain_below_40": 0
  },
  "low_confidence_segments": [
    {"page": 2, "text": "unclear...", "confidence": 0.55}
  ]
}</pre>
        </section>

        <!-- Queue System -->
        <section>
            <h2>Local Queue System</h2>
            <div class="mermaid">
stateDiagram-v2
    [*] --> Pending: Submit Job
    Pending --> Processing: Worker Picks Up
    Processing --> OCRComplete: OCR Done
    OCRComplete --> Organizing: Start Org
    Organizing --> Completed: Success
    Processing --> Failed: Error
    Organizing --> Failed: Error
    Failed --> Pending: Retry
    Pending --> Cancelled: User Cancel
    Completed --> [*]
    Cancelled --> [*]
            </div>

            <h3>Queue Features</h3>
            <div class="grid">
                <div class="card">
                    <h4>SQLite Backend</h4>
                    <p>Persistent, file-based, no external dependencies</p>
                </div>
                <div class="card">
                    <h4>Priority Levels</h4>
                    <p>Urgent, High, Normal, Low - process important jobs first</p>
                </div>
                <div class="card">
                    <h4>Visibility Timeout</h4>
                    <p>SQS-like behavior for distributed workers</p>
                </div>
                <div class="card">
                    <h4>Auto-Retry</h4>
                    <p>Failed jobs retry up to 3 times automatically</p>
                </div>
            </div>
        </section>

        <!-- Quick Start -->
        <section class="highlight">
            <h2>Quick Start Guide</h2>

            <div class="step">
                <div class="step-num">1</div>
                <div class="step-content">
                    <h4>Install Dependencies</h4>
                    <p><code>pip install -r requirements.txt</code></p>
                </div>
            </div>

            <div class="step">
                <div class="step-num">2</div>
                <div class="step-content">
                    <h4>Download Recommended Models</h4>
                    <p><code>python run.py download</code></p>
                </div>
            </div>

            <div class="step">
                <div class="step-num">3</div>
                <div class="step-content">
                    <h4>Start Web UI</h4>
                    <p><code>python run.py serve --port 8080</code></p>
                </div>
            </div>

            <div class="step">
                <div class="step-num">4</div>
                <div class="step-content">
                    <h4>Open Dashboard</h4>
                    <p>Navigate to <code>http://localhost:8080</code></p>
                </div>
            </div>

            <h3>CLI Commands</h3>
            <pre># Analyze a file and see recommended models
python run.py analyze document.pdf

# Submit a file for processing
python run.py submit invoice.pdf --priority high

# Process next job in queue
python run.py process

# Start background worker
python run.py worker

# Check queue status
python run.py status</pre>
        </section>

        <!-- File Structure -->
        <section>
            <h2>Project Structure</h2>
            <pre>idp_pipeline/
├── run.py                 # Main entry point
├── requirements.txt       # Dependencies
│
├── config/
│   ├── models_config.py   # All HuggingFace model definitions
│   └── intermediate_format.py  # OCR output format spec
│
├── models/
│   ├── smart_router.py    # Intelligent model selection
│   ├── ocr_engine.py      # OCR engine implementations
│   └── organizer_engine.py  # Organization engine implementations
│
├── queue/
│   └── local_queue.py     # SQLite-based job queue
│
├── api/
│   ├── pipeline.py        # Main processing pipeline
│   └── server.py          # FastAPI web server + dashboard
│
├── uploads/               # Uploaded files
├── output/                # Processed results
└── idp_queue.db          # SQLite queue database</pre>
        </section>

        <!-- Recommended Config -->
        <section class="highlight">
            <h2>Recommended Configuration</h2>
            <div class="grid">
                <div class="card">
                    <h4>Best ROI (Default)</h4>
                    <p>OCR: <span class="model-tag model-rec">Qwen2-VL-2B</span></p>
                    <p>Org: <span class="model-tag model-rec">Llama-3.2-3B</span></p>
                    <p style="margin-top:0.5rem;color:#10b981;">~14 GB VRAM | Good quality + Fast</p>
                </div>
                <div class="card">
                    <h4>Maximum Quality</h4>
                    <p>OCR: <span class="model-tag model-ocr">GOT-OCR 2.0</span></p>
                    <p>Org: <span class="model-tag model-org">Qwen2.5-7B</span></p>
                    <p style="margin-top:0.5rem;color:#f472b6;">~24 GB VRAM | Best accuracy</p>
                </div>
                <div class="card">
                    <h4>Maximum Speed</h4>
                    <p>OCR: <span class="model-tag model-ocr">Surya-OCR</span></p>
                    <p>Org: <span class="model-tag model-org">Qwen2.5-1.5B</span></p>
                    <p style="margin-top:0.5rem;color:#3b82f6;">~6 GB VRAM | Fastest</p>
                </div>
                <div class="card">
                    <h4>CPU Only</h4>
                    <p>OCR: <span class="model-tag model-ocr">TrOCR-Printed</span></p>
                    <p>Org: <span class="model-tag model-org">TinyLlama</span></p>
                    <p style="margin-top:0.5rem;color:#fbbf24;">No GPU needed | Acceptable quality</p>
                </div>
            </div>
        </section>

        <footer>
            <p>IDP Pipeline - 100% On-Premise Intelligent Document Processing</p>
            <p style="margin-top:0.5rem;">Generated: December 25, 2025 | Oracle ULTRATHINK Design</p>
        </footer>
    </div>

    <script>
        mermaid.initialize({
            startOnLoad: true,
            theme: 'dark',
            themeVariables: {
                primaryColor: '#7c3aed',
                primaryTextColor: '#e0e0e0',
                primaryBorderColor: '#4c1d95',
                lineColor: '#6b7280',
                secondaryColor: '#1e40af',
                tertiaryColor: '#0f172a',
                background: '#0f0f1a',
                mainBkg: '#1a1a2e',
                nodeBorder: '#4c1d95',
                clusterBkg: 'rgba(124,58,237,0.1)',
                clusterBorder: '#7c3aed',
                titleColor: '#e0e0e0',
                edgeLabelBackground: '#1a1a2e'
            },
            flowchart: {
                curve: 'basis',
                padding: 20
            },
            sequence: {
                actorMargin: 50,
                mirrorActors: false
            }
        });
    </script>
</body>
</html>
